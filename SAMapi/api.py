from fastapi import FastAPI, Request,File, UploadFile, HTTPException  # ç¡®ä¿UploadFileè¢«æ­£ç¡®å¯¼å…¥
from fastapi.responses import JSONResponse, HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

import uvicorn

import json
import jsonify
from datetime import datetime
import requests
from requests.models import Response

import torch
import torchvision.transforms as transforms

import os
import shutil
from uuid import uuid4
from PIL import Image
from jinja2 import Template, Environment, FileSystemLoader
from flask import render_template

import onnxruntime as ort
import numpy as np
from typing import Union
from copy import deepcopy

import cv2
import matplotlib.pyplot as plt

from main import SamDecoder, SamEncoder

# å…¨å±€å˜é‡
HOST = '127.0.0.1'
PORT = '8080'
port = 8080
DOMAIN = f"http://{HOST}:{PORT}"

# é…ç½®ä¸Šä¼ ç›®å½•ï¼Œå…¨å±€è®¾ç½®ä¸Šä¼ ç›®å½•
UPLOAD_DIRECTORY = "upload"
if not os.path.exists(UPLOAD_DIRECTORY):
    os.makedirs(UPLOAD_DIRECTORY)
PEOCESSED_DIRECTORY = "processed"
if not os.path.exists(PEOCESSED_DIRECTORY):
    os.makedirs(PEOCESSED_DIRECTORY)

# åŸå…ˆæ˜¯ä¼ å…¥å›¾ç‰‡è·¯å¾„ï¼Œè¾“å‡ºå¤„ç†åçš„å›¾ç‰‡çš„urlå¹¶ä¿å­˜å›¾ç‰‡ï¼Œå¯ä»¥è¿è¡Œï¼›åæ”¹ç§°è¾“å…¥fileç±»å‹

def load_model_path_or_repo_id(input_path_or_id: str):
    """
    æ ¹æ®æä¾›çš„è¾“å…¥åŠ è½½æ¨¡å‹è·¯å¾„æˆ–æ¨¡å‹ IDã€‚
    
    :param input_path_or_id: è¾“å…¥çš„è·¯å¾„æˆ–æ¨¡å‹ ID
    :return: è¿”å›å¤„ç†åçš„æ¨¡å‹è·¯å¾„æˆ–æ¨¡å‹ ID
    """
    if os.path.isdir(input_path_or_id):
        # å¦‚æœè¾“å…¥çš„æ˜¯ä¸€ä¸ªç›®å½•ï¼Œåˆ™è¿”å›è¯¥ç›®å½•è·¯å¾„
        return input_path_or_id
    else:
        # å¦åˆ™ï¼Œå‡è®¾è¾“å…¥çš„æ˜¯ Hugging Face Model Hub ä¸Šçš„æ¨¡å‹ ID
        return input_path_or_id

# ç¤ºä¾‹ä½¿ç”¨
input_path_or_id = "/path/to/local/folder"  # ç¤ºä¾‹æœ¬åœ°è·¯å¾„
# input_path_or_id = "hf-username/model-name"  # ç¤ºä¾‹æ¨¡å‹ ID

# å¤„ç†è¾“å…¥
processed_input = load_model_path_or_repo_id(input_path_or_id)
print(processed_input)

# è®¾ç½®è®¾å¤‡å‚æ•°
# Set the device      
DEVICE = "cpu" if torch.backends.mps.is_available() else "mps"
# To run PyTorch code on the GPU, use torch.device(â€œmpsâ€) analogous to torch.device(â€œcudaâ€) on an Nvidia GPU. 
print(f"Using device: {DEVICE}")
DEVICE_ID = "0"  # CUDAè®¾å¤‡IDï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä¸ºç©º
CUDA_DEVICE = f"{DEVICE}:{DEVICE_ID}" if DEVICE_ID else DEVICE  # ç»„åˆCUDAè®¾å¤‡ä¿¡æ¯

# æ¸…ç†GPUå†…å­˜å‡½æ•°
def torch_gc():
    if torch.cuda.is_available():  # æ£€æŸ¥æ˜¯å¦å¯ç”¨CUDA
        with torch.cuda.device(CUDA_DEVICE):  # æŒ‡å®šCUDAè®¾å¤‡
            torch.cuda.empty_cache()  # æ¸…ç©ºCUDAç¼“å­˜
            torch.cuda.ipc_collect()  # æ”¶é›†CUDAå†…å­˜ç¢ç‰‡

app = FastAPI() # åˆ›å»ºFastAPIåº”ç”¨
application = app # å°† app å¯¹è±¡æš´éœ²ä¸º ASGI åº”ç”¨ç¨‹åº

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
app.mount("/upload", StaticFiles(directory=UPLOAD_DIRECTORY), name="upload")
app.mount("/processed", StaticFiles(directory="processed"), name="processed")


# ä¹‹å‰æ˜¯è·¯ç”±çš„é—®é¢˜ï¼Œæ²¡æœ‰è½¬åˆ°/uploadä¸‹ï¼Œå› æ­¤ç›´æ¥æŠŠæ‰€æœ‰ä¸œè¥¿éƒ½å†™åœ¨/ä¸‹
# å›¾ç‰‡ä¸Šä¼ 
@app.get("/")
async def upload_image(request: Request):
    
    global encoder, decoder # å£°æ˜å…¨å±€å˜é‡ä»¥ä¾¿åœ¨å‡½æ•°å†…éƒ¨ä½¿ç”¨æ¨¡å‹
    print('sam decoder: ', SamDecoder)
    encoder = SamEncoder(
        model_path="../../SAM-Med2D/onnx_model/sam-med2d_b.encoder.onnx",
        warmup_epoch=3
    )
    print(f'*****encoder: {encoder}*****')
    decoder = SamDecoder(
        model_path="../../SAM-Med2D/onnx_model/sam-med2d_b.decoder.onnx",
    )
    print(f'*****decoder: {decoder}*****')


    json_post_raw = await request.json()  # è·å–POSTè¯·æ±‚çš„JSONæ•°æ®
    json_post = json.dumps(json_post_raw)  # å°†JSONæ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    json_post_list = json.loads(json_post)  # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºPythonå¯¹è±¡
    image_path = json_post_list.get("image_path")  # è·å–è¯·æ±‚ä¸­çš„image_path
    # history = json_post_list.get("history", [])  # è·å–è¯·æ±‚ä¸­çš„å†å²è®°å½•

    file = open(image_path, 'rb')
    original_file_name = os.path.basename(file.name)
    # original_file_name = file.name
    # è¯»å–æ–‡ä»¶å†…å®¹
    content = file.read()
    print(f"file: {file}\n")

    # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
    file_extension = original_file_name.split(".")[-1]
    if file_extension not in ("jpg", "jpeg", "png"):
        raise HTTPException(status_code=400, detail="Invalid file type")
    file_name = f"{uuid4()}.{file_extension}"
    file_path = os.path.join(UPLOAD_DIRECTORY, file_name)
    # å°†å†…å®¹ä¿å­˜åˆ°æ–°æ–‡ä»¶
    with open(file_path, 'wb') as new_file:
        new_file.write(content)
    print(f"æ–‡ä»¶å·²ä¿å­˜ä¸º {file_path}")

    # ğŸ‘‡éƒ½æ¥è‡ªSAM main.py ç”¨å·²ç»åœ¨mainä¸­åŠ è½½å¥½.onnxçš„æ¨¡å‹å¤„ç†å›¾ç‰‡ğŸ‘‡

    # SAMè‡ªå¸¦transformé¢„å¤„ç†å›¾ç‰‡
    '''Specifying a specific object with a point'''
    img_file = cv2.imread(file_path)
    img_embeddings = encoder(img_file)
    origin_image_size = img_file.shape[:2]

    point_coords = np.array([[162, 127]], dtype=np.float32)
    point_labels = np.array([1], dtype=np.float32)
    print(f"point_labels: {point_labels}\n")

    masks, _, logits = decoder.run(
        img_embeddings=img_embeddings,
        origin_image_size=origin_image_size,
        point_coords=point_coords,
        point_labels=point_labels
    )

    def show_mask(mask, ax, file_name, random_color=False):
        if random_color:
            color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
        else:
            color = np.array([30/255, 144/255, 255/255, 0.6])
        h, w = mask.shape[-2:]
        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
        print(f"mask_image:{np.shape(mask_image)}")
        # np.save(f'{file_name}.npy', mask_image)
        ax.imshow(mask_image)
    
    def show_points(coords, labels, ax, marker_size=375):
        pos_points = coords[labels==1]
        print(f"pos_points:{pos_points}")
        neg_points = coords[labels==0]
        ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)
        ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   
        

    plt.figure(figsize=(10,10))
    plt.imshow(img_file)
    show_mask(masks, plt.gca(),file_name)
    show_points(point_coords, point_labels, plt.gca())
    plt.axis('off')
    # ä¿å­˜æœ‰pointå’Œboxçš„å¤„ç†åçš„å›¾ç‰‡åˆ°PEOCESSED_DIRECTORY
    path_to_image = os.path.join(PEOCESSED_DIRECTORY, f"seg_{file_name}")
    plt.savefig(path_to_image)

    # ğŸ‘†éƒ½æ¥è‡ªSAM main.py ç”¨å·²ç»åœ¨mainä¸­åŠ è½½å¥½.onnxçš„æ¨¡å‹å¤„ç†å›¾ç‰‡ğŸ‘†
    
    # ç”Ÿæˆå›¾ç‰‡url
    path = f"/{PEOCESSED_DIRECTORY}/seg_{file_name}"
    seg_img_url = f"{DOMAIN}{path}"
    print('seg img url', seg_img_url)
    # response = {"image_url": seg_img_url}
    
    # æ„å»ºå“åº”JSON
    # æ„å»ºå“åº”å†…å®¹å­—å…¸
    now = datetime.now()  # è·å–å½“å‰æ—¶é—´
    time = now.strftime("%Y-%m-%d %H:%M:%S")  # æ ¼å¼åŒ–æ—¶é—´ä¸ºå­—ç¬¦ä¸²
    response_data = {
        "image_url": seg_img_url,
        "status": 200,
        "time": time
    }
    print('response data', response_data)
    print('type', type(response_data))
    # è·å–é¢„æµ‹ç»“æœ
    # class_id = predicted.item()
    # class_name = f"Class ID: {class_id}"  # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨åº”è¯¥æœ‰ä¸€ä¸ªç±»ååˆ—è¡¨

    # åˆ é™¤åŸæ–‡ä»¶
    # os.remove(file_path)

    # è¿”å›å“åº”
    # return FileResponse(path_to_image) # ç›´æ¥è¿”å›é™æ€æ–‡ä»¶ï¼Œæˆ–StreamingResponseé€å—æµå¼ä¼ è¾“æ–‡ä»¶
    #return json.dumps({"response": response})
    # è¿”å› JSON å“åº”
    return JSONResponse(content=response_data, status_code=200)

# å¯åŠ¨æœåŠ¡å™¨
# ä¸»å‡½æ•°å…¥å£
if __name__ == "__main__":
    # å¯¼å…¥å·²ç»é¢„è®­ç»ƒè¿‡çš„resnet18æ¨¡å‹
    # ç”±äºæš‚æ—¶ä¸éœ€è¦æ¨¡å‹å¾®è°ƒè€Œç›´æ¥ä¸‹è½½å®˜æ–¹é¢„è®­ç»ƒå‚æ•°ï¼Œæ•…è€Œæ³¨é‡Šæ‰
    # 'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth', è¿™æ˜¯å®˜æ–¹é¢„è®­ç»ƒå‚æ•°åœ°å€
    # model.load_state_dict(torch.load('https://download.pytorch.org/models/resnet18-5c106cde.pth'))
    
    # åœ¨ä¸»å‡½æ•°åŠ è½½æ¨¡å‹
    # Initialize the SAM-Med2D onnx model
    print(SamDecoder)
    encoder = SamEncoder(
        model_path="../../SAM-Med2D/onnx_model/sam-med2d_b.encoder.onnx",
        warmup_epoch=3
    )
    print("*"*5,encoder,"*"*5)
    decoder = SamDecoder(
        model_path="../../SAM-Med2D/onnx_model/sam-med2d_b.decoder.onnx",
    )
    print("*"*5,decoder,"*"*5)

    # åŠ è½½é¢„è®­ç»ƒçš„åˆ†è¯å™¨å’Œæ¨¡å‹
    # ä½†æ‰€å¤„ç†çš„æ•°æ®å¹¶éæ–‡æœ¬æ•°æ®ï¼Œåº”è¯¥ä¹Ÿå¯ä»¥ä¸ä½¿ç”¨åˆ†è¯å™¨

    # å¯åŠ¨FastAPIåº”ç”¨
    uvicorn.run(app='api:application', host=HOST, port=port, reload=True, workers=1)  # åœ¨æŒ‡å®šç«¯å£å’Œä¸»æœºä¸Šå¯åŠ¨åº”ç”¨

